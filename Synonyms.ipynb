{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonym detection\n",
    "This script output a list of candidates for sections 'synonyms' \n",
    "Potential synonyms must:\n",
    "    * Co-occur with similar sections (measured with tfidf metric, threshold fixed in minSimilarity parameter)\n",
    "    * Don't co-ocurr with between them more than a certain treshold (maxCooccur parameter)\n",
    "Additioanlly, other features are added for later evaluatio\n",
    "    * editdistance\n",
    "    * fasttext distance\n",
    "\n",
    "Inputs: \n",
    "    * Sections per article contained in ../gap/multiLanguageFromDumpsSec/sections-articles_lang.json, in format {articleId_1:[sec_a,sec_b...], articleId_2:[sec_x,sec_y], ..., article_n:[sec_i...]}\n",
    "    \n",
    "(The actual values uploaded to gdocs are generated with the .py version in this same folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import gzip\n",
    "import json\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import numpy as np\n",
    "import editdistance\n",
    "from fastText_multilingual.fasttext import FastVector\n",
    "import re\n",
    "\n",
    "def fasttextDistance(sec1,sec2,vectors):\n",
    "    '''\n",
    "    Take two sections, create a vector for each of them summing all the words\n",
    "    return cosine similarity\n",
    "    '''\n",
    "    sec1 = sec1.lower().split()\n",
    "    sec2 = sec2.lower().split()\n",
    "    sec1Vector  = np.sum([vectors[word] for word in sec1 if word in vectors],axis=0)/len(sec1)\n",
    "    sec2Vector  = np.sum([vectors[word] for word in sec2 if word in vectors],axis=0)/len(sec2)\n",
    "    distance  = vectors.cosine_similarity(sec1Vector,sec2Vector)\n",
    "    if not isinstance(distance,float): #when at least one of the sections is not the vectorial space, the result is 'nan'\n",
    "        return 0\n",
    "    else:\n",
    "        return vectors.cosine_similarity(sec1Vector,sec2Vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters \n",
    "\n",
    "#langs=['es','en','ar','ja','ru','fr']##define languages\n",
    "langs = ['ru']\n",
    "p = 0.75 #percentage of sections occurrences to be corevered \n",
    "maxCooccur = 3 #Maximum of coocurrences between pair of sections to be considered synonyms\n",
    "minSimilarity = .6# Miminum cosine similarity to be consider synonyms\n",
    "bucketSize = 50 #for stratified sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and save candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.ru.vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/dsaez/code/alignment/fastText_multilingual/fasttext.py:144: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Sec_A  \\\n",
      "78                Состав сельского поселения   \n",
      "154                    Международная карьера   \n",
      "72                                    Подвиг   \n",
      "138                                  В ролях   \n",
      "73                                       СМИ   \n",
      "245                          Основные работы   \n",
      "176                            Роли в театре   \n",
      "267                        Ординарии епархии   \n",
      "67                          Интересные факты   \n",
      "74                                   Фамилия   \n",
      "112                    Адрес местного совета   \n",
      "282                           Основные труды   \n",
      "218                         Известные жители   \n",
      "253                                Видеоклип   \n",
      "283                           Основные труды   \n",
      "238                          Жизнь и карьера   \n",
      "44               Известные жители и уроженцы   \n",
      "205                          Избранные труды   \n",
      "203                          Избранные труды   \n",
      "192                         Награды и звания   \n",
      "278                 Административное деление   \n",
      "45               Известные жители и уроженцы   \n",
      "230                       Премии и номинации   \n",
      "108              Административное устройство   \n",
      "284                           Основные труды   \n",
      "295                               Публикации   \n",
      "209                                   Актёры   \n",
      "197                            Научные труды   \n",
      "247                          Основные работы   \n",
      "32   Муниципально-территориальное устройство   \n",
      "..                                       ...   \n",
      "261                Социальная инфраструктура   \n",
      "40                          Социальная сфера   \n",
      "80                      Дополнительные факты   \n",
      "1                                    Природа   \n",
      "172                                    Улицы   \n",
      "37   Муниципально-территориальное устройство   \n",
      "86                                    Работы   \n",
      "24                                Археология   \n",
      "0                        Этимология названия   \n",
      "181                                  Эпизоды   \n",
      "182                                  Эпизоды   \n",
      "122                      Признание и награды   \n",
      "174                     Награды и достижения   \n",
      "178                                   Смерть   \n",
      "128                          Отзывы критиков   \n",
      "107              Административное устройство   \n",
      "110                             Список серий   \n",
      "17                    Избранная библиография   \n",
      "102                                Сочинения   \n",
      "148                         Научные интересы   \n",
      "132                    Обоснование символики   \n",
      "140                            Администрация   \n",
      "69                                    Подвиг   \n",
      "255                Политическая деятельность   \n",
      "262                Социальная инфраструктура   \n",
      "75                              Производство   \n",
      "22                                Археология   \n",
      "232                       Премии и номинации   \n",
      "38   Муниципально-территориальное устройство   \n",
      "34   Муниципально-территориальное устройство   \n",
      "\n",
      "                                       Sec_B  coOccurs  editDistance  \\\n",
      "78               Состав городского поселения         0             5   \n",
      "154                        Карьера в сборной         0            18   \n",
      "72                                 Документы         1             8   \n",
      "138                                   Актёры         0             7   \n",
      "73              Средства массовой информации         0            27   \n",
      "245                           Основные труды         0             5   \n",
      "176                       Театральные работы         0            16   \n",
      "267                             Прославление         0            13   \n",
      "67                                     Факты         2            12   \n",
      "74                          Носители фамилии         0            11   \n",
      "112                            Местный совет         0            11   \n",
      "282                               Публикации         3            14   \n",
      "218              Известные уроженцы и жители         0            11   \n",
      "253                        Музыкальное видео         1            15   \n",
      "283                     Избранные публикации         1            16   \n",
      "238                       Театральные работы         1            16   \n",
      "44                        Известные уроженцы         0             9   \n",
      "205                     Избранные публикации         0            10   \n",
      "203                           Основные труды         0             6   \n",
      "192                         Звания и награды         0            14   \n",
      "278  Административно-территориальное деление         0            15   \n",
      "45                          Известные жители         0            11   \n",
      "230                      Награды и номинации         0             7   \n",
      "108                 Административное деление         3            10   \n",
      "284                      Основные публикации         2            10   \n",
      "295                     Избранные публикации         0            11   \n",
      "209                          Роли озвучивали         0            15   \n",
      "197                           Основные труды         2             5   \n",
      "247                     Избранные публикации         1            15   \n",
      "32               Административное устройство         0            19   \n",
      "..                                       ...       ...           ...   \n",
      "261                                   Власть         0            21   \n",
      "40       Достопримечательности (фотогалерея)         0            25   \n",
      "80                        Премии и номинации         0            17   \n",
      "1                                     Власть         3             7   \n",
      "172  Административно-территориальное деление         0            38   \n",
      "37       Достопримечательности (фотогалерея)         0            33   \n",
      "86                               Брак и дети         0             9   \n",
      "24              Средства массовой информации         2            24   \n",
      "0                 Взаимодействие с человеком         2            20   \n",
      "181                                Номинации         1             8   \n",
      "182                Дополнительная информация         0            22   \n",
      "122                         Премии и награды         0             6   \n",
      "174                               Достижения         0            11   \n",
      "178                                   Гибель         0             5   \n",
      "128                                  Критика         0            10   \n",
      "107                       География и климат         3            22   \n",
      "110                                  Эпизоды         2             9   \n",
      "17               Педагогическая деятельность         3            24   \n",
      "102                      Основные публикации         0            16   \n",
      "148                             Произведения         1            14   \n",
      "132                          Распространение         0            18   \n",
      "140              Известные уроженцы и жители         3            23   \n",
      "69                           Воинские звания         0            12   \n",
      "255                     Дипломатический ранг         1            19   \n",
      "262                 Административное деление         2            23   \n",
      "75                               Экранизация         1            11   \n",
      "22                         Транспортная сеть         0            14   \n",
      "232                Дополнительная информация         0            18   \n",
      "38                          Состав поселения         0            34   \n",
      "34                             Администрация         1            33   \n",
      "\n",
      "     isSubSet  tfIdfSimilarity  vectorDistance  \n",
      "78      False             0.99        0.917500  \n",
      "154     False             0.98        0.695776  \n",
      "72      False             0.95        0.352857  \n",
      "138     False             0.94        0.567853  \n",
      "73      False             0.94        0.557246  \n",
      "245     False             0.92        0.796731  \n",
      "176     False             0.92        0.537255  \n",
      "267     False             0.92        0.336689  \n",
      "67       True             0.91        0.916544  \n",
      "74      False             0.91        0.839571  \n",
      "112     False             0.91        0.580018  \n",
      "282     False             0.90        0.445744  \n",
      "218     False             0.89        0.926242  \n",
      "253     False             0.89        0.589854  \n",
      "283     False             0.89        0.549820  \n",
      "238     False             0.89        0.354101  \n",
      "44      False             0.88        0.936217  \n",
      "205     False             0.88        0.831408  \n",
      "203     False             0.88        0.785083  \n",
      "192     False             0.87        1.000000  \n",
      "278     False             0.87        0.941399  \n",
      "45       True             0.87        0.926242  \n",
      "230     False             0.87        0.910272  \n",
      "108     False             0.87        0.836479  \n",
      "284     False             0.87        0.795740  \n",
      "295      True             0.87        0.788048  \n",
      "209     False             0.87        0.588302  \n",
      "197     False             0.86        0.843683  \n",
      "247     False             0.86        0.497384  \n",
      "32      False             0.85        0.837979  \n",
      "..        ...              ...             ...  \n",
      "261     False             0.61        0.287918  \n",
      "40      False             0.61        0.283365  \n",
      "80      False             0.61        0.275903  \n",
      "1       False             0.61        0.262751  \n",
      "172     False             0.61        0.228433  \n",
      "37      False             0.61        0.205814  \n",
      "86      False             0.61        0.185066  \n",
      "24      False             0.61        0.180158  \n",
      "0       False             0.61        0.172738  \n",
      "181     False             0.61        0.166300  \n",
      "182     False             0.61        0.147692  \n",
      "122     False             0.60        0.861082  \n",
      "174      True             0.60        0.791831  \n",
      "178     False             0.60        0.725177  \n",
      "128     False             0.60        0.612402  \n",
      "107     False             0.60        0.477102  \n",
      "110     False             0.60        0.464523  \n",
      "17      False             0.60        0.445924  \n",
      "102     False             0.60        0.432316  \n",
      "148     False             0.60        0.349579  \n",
      "132     False             0.60        0.338293  \n",
      "140     False             0.60        0.338089  \n",
      "69      False             0.60        0.328725  \n",
      "255     False             0.60        0.319111  \n",
      "262     False             0.60        0.316837  \n",
      "75      False             0.60        0.276399  \n",
      "22      False             0.60        0.267328  \n",
      "232     False             0.60        0.245086  \n",
      "38      False             0.60        0.225116  \n",
      "34      False             0.60        0.178875  \n",
      "\n",
      "[299 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 coOccurs  editDistance  isSubSet  tfIdfSimilarity  \\\n",
      "coOccurs         1.000000      0.137955 -0.076813        -0.080079   \n",
      "editDistance     0.137955      1.000000 -0.247429        -0.250520   \n",
      "isSubSet        -0.076813     -0.247429  1.000000         0.082985   \n",
      "tfIdfSimilarity -0.080079     -0.250520  0.082985         1.000000   \n",
      "vectorDistance  -0.174302     -0.489959  0.478896         0.415833   \n",
      "\n",
      "                 vectorDistance  \n",
      "coOccurs              -0.174302  \n",
      "editDistance          -0.489959  \n",
      "isSubSet               0.478896  \n",
      "tfIdfSimilarity        0.415833  \n",
      "vectorDistance         1.000000  \n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    output = []\n",
    "    coOccur = {}\n",
    "    sectionsAll = []\n",
    "    #Load Sections\n",
    "    with open('../gap/multiLanguageFromDumpsSec/sections-articles_%s.json' % lang) as f: \n",
    "        sections = json.load(f)\n",
    "    ##get most frequent sections\n",
    "    for secs in sections.values():\n",
    "        for secName in secs:\n",
    "                cleanSection = re.sub('[=\\]\\[]','',secName).strip()\n",
    "                if cleanSection: #check that string is not empty\n",
    "                    sectionsAll.append(cleanSection.strip())\n",
    "    sectionsFreq = Counter(sectionsAll)\n",
    "    total = sum(sectionsFreq.values())\n",
    "    acc =0\n",
    "    secsToEval = []\n",
    "    for n,(sec,freq) in enumerate(sectionsFreq.most_common()):\n",
    "        acc+= freq\n",
    "        secsToEval.append(sec)\n",
    "\n",
    "        if acc/total > p: #using sections that cover 80% of total\n",
    "                break\n",
    "    ## Get fasttext vectors for lang\n",
    "    wordVectors = FastVector(vector_file='fastText_multilingual/vectors/wiki.%s.vec' % lang)\n",
    "    ## Count Coocurrences of sections\n",
    "    for page,secs in sections.items():\n",
    "        for sec1,sec2 in combinations(secs,2):\n",
    "                coOccur[sec1] = coOccur.get(sec1,{})\n",
    "                coOccur[sec2] = coOccur.get(sec2,{})\n",
    "                coOccur[sec1][sec2] = coOccur[sec1].get(sec2,0)\n",
    "                coOccur[sec2][sec1] = coOccur[sec2].get(sec1,0)\n",
    "                coOccur[sec1][sec2] += 1\n",
    "                coOccur[sec2][sec1] += 1\n",
    "    \n",
    "    #Compute the IDF, different from working with words, sections names can just occur ones per doc\n",
    "    idf = {}\n",
    "    for sec in coOccur.keys():\n",
    "        idf[sec] = math.log(len(sectionsFreq) / (1 + sectionsFreq[sec]))\n",
    "    #compute TFIDF\n",
    "    tfidf = {}\n",
    "    for sec1,secs in coOccur.items():\n",
    "        if (sec1 in secsToEval):\n",
    "            tfidf[sec1] = {}\n",
    "            for sec2,tf in secs.items():\n",
    "                tfidf[sec1][sec2] = tf * idf[sec2]\n",
    "\n",
    "    #Transform dictionary to sparse matrix\n",
    "    v = DictVectorizer()\n",
    "    tfidfVectors = v.fit_transform(tfidf.values())\n",
    "    tfidfKeys = tfidf.keys()\n",
    "    \n",
    "    #Compute pairwise cosine similariry\n",
    "    S = cosine_similarity(tfidfVectors)\n",
    "    \n",
    "    #Find most similar pairs\n",
    "    np.fill_diagonal(S, -1) #'remove' diagional \n",
    "    tri_upper_diag = np.triu(S, k=0) #given that the matrix is symetric I take just thre upper triangle\n",
    "    mostSimilar = np.where( tri_upper_diag > minSimilarity)\n",
    "    \n",
    "\n",
    "    indexes = {n:k for n,k in enumerate(tfidfKeys)}\n",
    "    for sec1,sec2 in zip(mostSimilar[0],mostSimilar[1]):\n",
    "        if coOccur[indexes[sec2]].get(indexes[sec1],0) <= maxCooccur:\n",
    "            sec1Name = indexes[sec1]\n",
    "            sec2Name = indexes[sec2]\n",
    "            tfIdfsimilarity = tri_upper_diag[sec1][sec2]\n",
    "            editDistance = editdistance.eval(sec1Name, sec2Name)\n",
    "            isSubSet = (sec1Name.lower() in sec2Name.lower()) or (sec2Name.lower() in sec1Name.lower()) \n",
    "            vectorDistance = fasttextDistance(sec1Name,sec2Name,wordVectors)\n",
    "            output.append({'Sec_A':indexes[sec1],'Sec_B':indexes[sec2],\n",
    "                           'coOccurs':coOccur[indexes[sec2]].get(indexes[sec1],0),\n",
    "                           'tfIdfSimilarity':round(tri_upper_diag[sec1][sec2],2),\n",
    "                           'editDistance': editDistance,\n",
    "                           'isSubSet': isSubSet,\n",
    "                           'vectorDistance':vectorDistance,                           \n",
    "                          })\n",
    "    #save results in xls\n",
    "    df = pd.DataFrame(output)\n",
    "    df = df.sort_values(['tfIdfSimilarity','vectorDistance','editDistance','isSubSet'],ascending=False)\n",
    "    print(df)\n",
    "    df.to_excel('%sSynonyms.xls' % lang,index=False)\n",
    "    print(df.corr())\n",
    "    dfs[lang] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('%sSynonyms.csv' % lang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statrified sample\n",
    "\n",
    "* Here, we repeat the same procedure, but generating an stratified sample considering tfidf and fasttext similarity.\n",
    "* Buckets are defined by rounding to the first decimal of those metrics (ex. tfidfSimilariry = 0.11231, is in the bucket tfidfSimilarity 0.1, for each metric whe consider ten buckets 0.1, 0.2 ..., 1 and the size of each bucket is defined by the bucketSize parameter, in this example we use bucketSize=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.es.vec\n",
      "en\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.en.vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/dsaez/code/alignment/fastText_multilingual/fasttext.py:144: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n",
      "/srv/home/dsaez/code/alignment/fastText_multilingual/fasttext.py:144: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.ar.vec\n",
      "ja\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.ja.vec\n",
      "ru\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.ru.vec\n",
      "fr\n",
      "reading word vectors from fastText_multilingual/vectors/wiki.fr.vec\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    toDF = []\n",
    "    coOccur = {}\n",
    "    sectionsAll = []\n",
    "    #Load Sections\n",
    "    with open('../gap/multiLanguageFromDumpsSec/sections-articles_%s.json' % lang) as f: \n",
    "        sections = json.load(f)\n",
    "    ##get most frequent sections\n",
    "    for secs in sections.values():\n",
    "        for secName in secs:\n",
    "                cleanSection = re.sub('[=\\]\\[]','',secName).strip()\n",
    "                if cleanSection:#check string is not empty\n",
    "                    sectionsAll.append(cleanSection.strip())\n",
    "    sectionsFreq = Counter(sectionsAll)\n",
    "    total = sum(sectionsFreq.values())\n",
    "    acc =0\n",
    "    secsToEval = []\n",
    "    for n,(sec,freq) in enumerate(sectionsFreq.most_common()):\n",
    "        acc+= freq\n",
    "        secsToEval.append(sec)\n",
    "\n",
    "        if acc/total > p: #using sections that cover 80% of total\n",
    "                break\n",
    "    ## Get fasttext vectors for lang\n",
    "    wordVectors = FastVector(vector_file='fastText_multilingual/vectors/wiki.%s.vec' % lang)\n",
    "    ## Count Coocurrences of sections\n",
    "    for page,secs in sections.items():\n",
    "        for sec1,sec2 in combinations(secs,2):\n",
    "                coOccur[sec1] = coOccur.get(sec1,{})\n",
    "                coOccur[sec2] = coOccur.get(sec2,{})\n",
    "                coOccur[sec1][sec2] = coOccur[sec1].get(sec2,0)\n",
    "                coOccur[sec2][sec1] = coOccur[sec2].get(sec1,0)\n",
    "                coOccur[sec1][sec2] += 1\n",
    "                coOccur[sec2][sec1] += 1\n",
    "    \n",
    "    #Compute the IDF, different from working with words, sections names can just occur ones per doc\n",
    "    idf = {}\n",
    "    for sec in coOccur.keys():\n",
    "        idf[sec] = math.log(len(sectionsFreq) / (1 + sectionsFreq[sec]))\n",
    "    #compute TFIDF\n",
    "    tfidf = {}\n",
    "    for sec1,secs in coOccur.items():\n",
    "        if (sec1 in secsToEval):\n",
    "            tfidf[sec1] = {}\n",
    "            for sec2,tf in secs.items():\n",
    "                tfidf[sec1][sec2] = tf * idf[sec2]\n",
    "\n",
    "    #Transform dictionary to sparse matrix\n",
    "    v = DictVectorizer()\n",
    "    tfidfVectors = v.fit_transform(tfidf.values())\n",
    "    tfidfKeys = tfidf.keys()\n",
    "    \n",
    "    #Compute pairwise cosine similariry\n",
    "    S = cosine_similarity(tfidfVectors)\n",
    "    \n",
    "    #Get the upper matrix, and remove diagonal\n",
    "    np.fill_diagonal(S, -2) #'remove' diagional \n",
    "    tri_upper_diag = np.triu(S, k=0) #given that the matrix is symetric I take just thre upper triangle\n",
    "    \n",
    "    indexes = {n:k for n,k in enumerate(tfidfKeys)}\n",
    "    for x in range(tri_upper_diag.shape[0]):\n",
    "        for y in range(tri_upper_diag.shape[1]):\n",
    "            if coOccur[indexes[x]].get(indexes[y],0) <= maxCooccur:\n",
    "                if tri_upper_diag[x][y] > 0:\n",
    "                    sec1Name = indexes[x]\n",
    "                    sec2Name = indexes[y]\n",
    "                    toDF.append({'Sec_A':sec1Name,'Sec_B':sec2Name,'tfIdfSimilarity':round(tri_upper_diag[x][y],1) } )\n",
    "    df = pd.DataFrame(toDF)\n",
    "    df['vectorDistance'] = df.apply(lambda row: round(fasttextDistance(row['Sec_A'],row['Sec_B'],wordVectors),1), axis=1)\n",
    "\n",
    "    dfStratifiedTF = df.groupby('tfIdfSimilarity', group_keys=False).apply(lambda x: x.sample(min(len(x),bucketSize)))\n",
    "    dfStratifiedVec =  df.groupby('tfIdfSimilarity', group_keys=False).apply(lambda x: x.sample(min(len(x),bucketSize)))\n",
    "    dfStratified = pd.concat([dfStratifiedTF,dfStratifiedVec]).drop_duplicates()\n",
    "    dfStratified['editDistance'] = dfStratified.apply(lambda row: editdistance.eval(row['Sec_A'],row['Sec_B']), axis=1)\n",
    "    dfStratified['coOccurs'] = dfStratified.apply(lambda row: coOccur[row['Sec_A']].get(row['Sec_B'],0), axis=1)\n",
    "    dfStratified['isSubSet'] = dfStratified.apply(lambda row:(row['Sec_A'].lower() in row['Sec_B'].lower()) or (row['Sec_B'].lower() in row['Sec_A'].lower()),axis=1)\n",
    "    dfStratified.to_excel('%sSynonyms_Stratified.xls' % lang,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task\n",
    "\n",
    "Using the manually labeled pairs, we train a set of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with russian\n",
    "\n",
    "#### Join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "features = pd.read_excel('ruSynonyms_Stratified.xls')\n",
    "labels = pd.read_csv('Synonym mapping - ru-r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru = pd.merge(labels, features, how='left', left_on=['Section title 1', 'Section title 2'],right_on=['Sec_A', 'Sec_B'])\n",
    "ru = data[['Section title 1', 'Section title 2','Relation - Assessment 1', 'coOccurs','editDistance','isSubSet','tfIdfSimilarity','vectorDistance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ru['Relation - Assessment 1']\n",
    "X = ru[['coOccurs','editDistance','isSubSet','tfIdfSimilarity','vectorDistance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[212,   2,   2],\n",
       "       [  7,   1,   7],\n",
       "       [ 13,   4,  30]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "ruModel = XGBClassifier()\n",
    "ruModel.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = ruModel.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coOccurs', 0.087499999),\n",
       " ('editDistance', 0.40000001),\n",
       " ('isSubSet', 0.00125),\n",
       " ('tfIdfSimilarity', 0.23875),\n",
       " ('vectorDistance', 0.27250001)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_test.columns,model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "TODO: gridSearch for set find parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[209,   5,   2],\n",
       "       [  7,   2,   6],\n",
       "       [ 10,  11,  26]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ruClf = RandomForestClassifier(n_estimators=40)\n",
    "ruClf.fit(X_train, y_train)\n",
    "y_pred = ruClf.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coOccurs', 0.072080550020187456),\n",
       " ('editDistance', 0.2012911169503504),\n",
       " ('isSubSet', 0.043929281870681361),\n",
       " ('tfIdfSimilarity', 0.21249577274475598),\n",
       " ('vectorDistance', 0.47020327841402471)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_test.columns,clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_excel('ruSynonyms_Stratified.xls')\n",
    "labels = pd.read_csv('Synonym mapping - ru-r1.csv')\n",
    "\n",
    "en = pd.merge(labels, features, how='left', left_on=['Section title 1', 'Section title 2'],right_on=['Sec_A', 'Sec_B'])\n",
    "en = data[['Section title 1', 'Section title 2','Relation - Assessment 1', 'coOccurs','editDistance','isSubSet','tfIdfSimilarity','vectorDistance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Russian Model in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[652,   5,   2],\n",
       "       [ 10,  49,   6],\n",
       "       [ 10,  11,  95]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_en = en['Relation - Assessment 1']\n",
    "X_en = en[['coOccurs','editDistance','isSubSet','tfIdfSimilarity','vectorDistance']]\n",
    "y_pred_en = ruClf.predict(X_en)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_en, y_pred_en )\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "confusion_matrix(Y_en, y_pred_en )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[649,   3,   7],\n",
       "       [ 26,  19,  20],\n",
       "       [ 16,   5,  95]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = ruModel.predict(X_en)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_en, y_pred_en )\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "confusion_matrix(Y_en, y_pred_en )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model in English and test in Russsian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.21%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[656,   1,   2],\n",
       "       [  7,  56,   2],\n",
       "       [  3,   0, 113]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enClf = RandomForestClassifier(n_estimators=40)\n",
    "enClf.fit(X_en, Y_en)\n",
    "y_pred = enClf.predict(X) # X is the russian data\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_pred, Y)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "confusion_matrix(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coOccurs', 0.065012961955359924),\n",
       " ('editDistance', 0.21834566899919791),\n",
       " ('isSubSet', 0.064010429355475282),\n",
       " ('tfIdfSimilarity', 0.24647845816786926),\n",
       " ('vectorDistance', 0.40615248152209754)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X.columns,enClf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
