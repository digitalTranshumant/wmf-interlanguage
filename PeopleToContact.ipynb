{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find list of bilinguals candidates\n",
    "\n",
    "Here we find users to be contacted for the translation task. We combine two strategies:\n",
    "\n",
    "* Users self reporting their languages skills (3 or more) in Babel, and editing at least 100 times in each languages.\n",
    "* The top users using the translation tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup langs\n",
    "\n",
    "langs = ['fr','es','ru','ar','en','ja'] #languages included\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Babel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "babel = pd.read_csv('allwiki-babel-out-users.tsv.tar.gz',sep='\\t',index_col=0)\n",
    "babel['username'] = babel.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['3','4','5','N']  #babel labels accepted\n",
    "minEdits = 10 # olunteers need to have edited more than %minEdits times in both langs\n",
    "usersBabel =[]\n",
    "for lang1,lang2 in combinations(langs,2):\n",
    "    babel[babel[lang1+'_proficiency'].isin(levels)]\n",
    "    tmp = babel[babel[lang1+'_proficiency'].isin(levels)]\n",
    "    tmp = tmp[tmp[lang2+'_proficiency'].isin(levels)]\n",
    "    tmp  = tmp[tmp['%swiki_editcount' % lang1] > minEdits]\n",
    "    tmp  = tmp[tmp['%swiki_editcount' % lang2] > minEdits]\n",
    "    tmp['lang1'] = lang1\n",
    "    tmp['lang2'] = lang2\n",
    "    usersBabel.append(tmp[['username','lang1','lang2']][0:5])\n",
    "    \n",
    "outputBabel = pd.concat(usersBabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation tool (Cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine    \n",
    "from itertools import permutations\n",
    "\n",
    "                                            \n",
    "engine = create_engine('mysql://XXXXX@replicas/wikishared')\n",
    "usersCx = []\n",
    "for lang1,lang2 in permutations(langs,2):\n",
    "    query = \"\"\"\n",
    "    SELECT trans.cnt as cnt ,global.gu_id,global.gu_name as username FROM (SELECT translation_started_by,  count(translation_target_title) as cnt FROM cx_translations WHERE (translation_status = 'published' OR translation_target_url IS NOT null) AND  translation_target_language = '%s' AND translation_source_language='%s' GROUP BY translation_started_by ORDER BY count(translation_target_title) DESC LIMIT 5) AS trans INNER JOIN centralauth.globaluser as global ON global.gu_id = trans.translation_started_by WHERE cnt >10;\n",
    "    \"\"\" % (lang1,lang2)\n",
    "    tmp = pd.read_sql_query(query,engine)\n",
    "    tmp['lang1'] = lang1\n",
    "    tmp['lang2'] = lang2\n",
    "    tmp['username'] = tmp.username.str.decode(\"utf-8\")\n",
    "    tmp['Translations'] = tmp.cnt\n",
    "    usersCx.append(tmp[['username','lang1','lang2','Translations']][0:5])\n",
    "outputCx= pd.concat(usersCx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = pd.concat([outputCx,outputBabel]).drop_duplicates(subset=['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel('peopleToContact.xls',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['pairs'] =  output[['lang1', 'lang2']].apply(lambda x: ','.join(sorted(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "es,fr    15\n",
       "en,es    14\n",
       "en,fr    13\n",
       "en,ru    10\n",
       "ar,fr     9\n",
       "es,ru     6\n",
       "en,ja     5\n",
       "ar,en     4\n",
       "fr,ru     3\n",
       "fr,ja     2\n",
       "ar,es     2\n",
       "Name: pairs, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pairs.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get at least 6 candidates pair for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
